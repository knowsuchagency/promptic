interactions:
- request:
    body: '{"contents": [{"role": "user", "parts": [{"text": "Just respond to: Hello!"}]}],
      "generationConfig": {"temperature": 0}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '120'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - litellm/1.56.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:streamGenerateContent?alt=sse&key=REDACTED
  response:
    body:
      string: "data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"Hello\"}],\"role\":
        \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 7,\"totalTokenCount\":
        7,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 7}]},\"modelVersion\":
        \"gemini-2.0-flash\",\"responseId\": \"vwVmaPPVD5ffmNAP64W5QA\"}\r\n\r\ndata:
        {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"!\\n\"}],\"role\":
        \"model\"},\"finishReason\": \"STOP\"}],\"usageMetadata\": {\"promptTokenCount\":
        6,\"candidatesTokenCount\": 3,\"totalTokenCount\": 9,\"promptTokensDetails\":
        [{\"modality\": \"TEXT\",\"tokenCount\": 6}],\"candidatesTokensDetails\":
        [{\"modality\": \"TEXT\",\"tokenCount\": 3}]},\"modelVersion\": \"gemini-2.0-flash\",\"responseId\":
        \"vwVmaPPVD5ffmNAP64W5QA\"}\r\n\r\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Disposition:
      - attachment
      Content-Type:
      - text/event-stream
      Date:
      - Thu, 03 Jul 2025 04:23:27 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=390
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
    status:
      code: 200
      message: OK
- request:
    body: '{"contents": [{"role": "user", "parts": [{"text": "Just respond to: Hello!"}]},
      {"role": "model", "parts": [{"text": "Hello!\n"}]}, {"role": "user", "parts":
      [{"text": "Just respond to: How are you?"}]}], "generationConfig": {"temperature":
      0}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '244'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - litellm/1.56.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:streamGenerateContent?alt=sse&key=REDACTED
  response:
    body:
      string: "data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"I\"}],\"role\":
        \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 20,\"totalTokenCount\":
        20,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 20}]},\"modelVersion\":
        \"gemini-2.0-flash\",\"responseId\": \"vwVmaMKyL5ffmNAP64W5QA\"}\r\n\r\ndata:
        {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" am doing well,
        thank you for asking! How are you?\\n\"}],\"role\": \"model\"},\"finishReason\":
        \"STOP\"}],\"usageMetadata\": {\"promptTokenCount\": 17,\"candidatesTokenCount\":
        15,\"totalTokenCount\": 32,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\":
        17}],\"candidatesTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\":
        15}]},\"modelVersion\": \"gemini-2.0-flash\",\"responseId\": \"vwVmaMKyL5ffmNAP64W5QA\"}\r\n\r\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Disposition:
      - attachment
      Content-Type:
      - text/event-stream
      Date:
      - Thu, 03 Jul 2025 04:23:28 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=375
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
    status:
      code: 200
      message: OK
version: 1
