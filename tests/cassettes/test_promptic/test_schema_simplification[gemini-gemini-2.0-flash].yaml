interactions:
- request:
    body: '{"contents": [{"role": "user", "parts": [{"text": "Create a person named
      Alice who is 30 years old."}, {"text": "Format your response according to this
      JSON schema:\n```json\n{\n  \"properties\": {\n    \"name\": {\n      \"type\":
      \"string\"\n    },\n    \"age\": {\n      \"type\": \"integer\"\n    }\n  },\n  \"required\":
      [\n    \"name\",\n    \"age\"\n  ],\n  \"type\": \"object\"\n}\n```\n\nProvide
      the result enclosed in triple backticks with ''json'' on the first line. Don''t
      put control characters in the wrong place or the JSON will be invalid."}]}],
      "generationConfig": {"temperature": 0}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '598'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - litellm/1.56.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=REDACTED
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"```json\\n{\\n  \\\"name\\\": \\\"Alice\\\",\\n
        \ \\\"age\\\": 30\\n}\\n```\"\n          }\n        ],\n        \"role\":
        \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"avgLogprobs\":
        1.1357672822972138e-06\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\":
        136,\n    \"candidatesTokenCount\": 24,\n    \"totalTokenCount\": 160,\n    \"promptTokensDetails\":
        [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 136\n
        \     }\n    ],\n    \"candidatesTokensDetails\": [\n      {\n        \"modality\":
        \"TEXT\",\n        \"tokenCount\": 24\n      }\n    ]\n  },\n  \"modelVersion\":
        \"gemini-2.0-flash\",\n  \"responseId\": \"-AlmaIXQBOGg1PIP1dfd6Ao\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Thu, 03 Jul 2025 04:41:28 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=477
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '708'
    status:
      code: 200
      message: OK
- request:
    body: '{"contents": [{"role": "user", "parts": [{"text": "Create a person named
      Bob who is 25 years old."}, {"text": "Format your response according to this
      JSON schema:\n```json\n{\n  \"description\": \"Test model with metadata\",\n  \"properties\":
      {\n    \"name\": {\n      \"title\": \"Name\",\n      \"type\": \"string\"\n    },\n    \"age\":
      {\n      \"title\": \"Age\",\n      \"type\": \"integer\"\n    }\n  },\n  \"required\":
      [\n    \"name\",\n    \"age\"\n  ],\n  \"title\": \"TestModel\",\n  \"type\":
      \"object\"\n}\n```\n\nProvide the result enclosed in triple backticks with ''json''
      on the first line. Don''t put control characters in the wrong place or the JSON
      will be invalid."}]}], "generationConfig": {"temperature": 0}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '730'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - litellm/1.56.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=REDACTED
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"```json\\n{\\n  \\\"name\\\": \\\"Bob\\\",\\n
        \ \\\"age\\\": 25\\n}\\n```\"\n          }\n        ],\n        \"role\":
        \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"avgLogprobs\":
        1.1165830073878169e-06\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\":
        172,\n    \"candidatesTokenCount\": 24,\n    \"totalTokenCount\": 196,\n    \"promptTokensDetails\":
        [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 172\n
        \     }\n    ],\n    \"candidatesTokensDetails\": [\n      {\n        \"modality\":
        \"TEXT\",\n        \"tokenCount\": 24\n      }\n    ]\n  },\n  \"modelVersion\":
        \"gemini-2.0-flash\",\n  \"responseId\": \"-AlmaIfHLJH92PgPmL2xkQo\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Thu, 03 Jul 2025 04:41:29 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=406
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '706'
    status:
      code: 200
      message: OK
version: 1
