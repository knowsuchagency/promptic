interactions:
- request:
    body: '{"contents": [{"role": "user", "parts": [{"text": "What is the capital
      of France?"}]}], "generationConfig": {"temperature": 0}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '127'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - litellm/1.56.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=REDACTED
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"The capital of France is **Paris**.\\n\"\n
        \         }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\":
        \"STOP\",\n      \"avgLogprobs\": -0.027038529515266418\n    }\n  ],\n  \"usageMetadata\":
        {\n    \"promptTokenCount\": 7,\n    \"candidatesTokenCount\": 9,\n    \"totalTokenCount\":
        16,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n
        \       \"tokenCount\": 7\n      }\n    ],\n    \"candidatesTokensDetails\":
        [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 9\n      }\n
        \   ]\n  },\n  \"modelVersion\": \"gemini-2.0-flash\",\n  \"responseId\":
        \"3AlmaJWtOp7_2PgP9tmQsAc\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Thu, 03 Jul 2025 04:41:01 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=407
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '680'
    status:
      code: 200
      message: OK
- request:
    body: '{"contents": [{"role": "user", "parts": [{"text": "What is the capital
      of France?"}]}, {"role": "model", "parts": [{"text": "The capital of France
      is Paris."}]}, {"role": "user", "parts": [{"text": "What is its population?"}]}],
      "generationConfig": {"temperature": 0}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '268'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - litellm/1.56.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=REDACTED
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"The population of Paris is a bit tricky
        to pin down to one number, as it depends on what area you're considering:\\n\\n*
        \  **City of Paris (within the city limits):** Around 2.1 million people.\\n*
        \  **Greater Paris (M\xE9tropole du Grand Paris):** Around 7 million people.\\n*
        \  **Paris Metropolitan Area (\xCEle-de-France region):** Around 12 million
        people.\\n\\nSo, depending on the context, the population could be any of
        those figures. The most commonly cited figure is probably the **City of Paris
        at around 2.1 million**.\\n\"\n          }\n        ],\n        \"role\":
        \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"avgLogprobs\":
        -0.1764146217933068\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\":
        19,\n    \"candidatesTokenCount\": 130,\n    \"totalTokenCount\": 149,\n    \"promptTokensDetails\":
        [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 19\n
        \     }\n    ],\n    \"candidatesTokensDetails\": [\n      {\n        \"modality\":
        \"TEXT\",\n        \"tokenCount\": 130\n      }\n    ]\n  },\n  \"modelVersion\":
        \"gemini-2.0-flash\",\n  \"responseId\": \"3QlmaLqFIZffmNAP64W5QA\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Thu, 03 Jul 2025 04:41:02 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=1233
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '1168'
    status:
      code: 200
      message: OK
- request:
    body: '{"contents": [{"role": "user", "parts": [{"text": "What is the capital
      of France?"}]}], "system_instruction": {"parts": [{"text": "You are a geography
      expert"}]}, "generationConfig": {"temperature": 0}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '202'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - litellm/1.56.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=REDACTED
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"The capital of France is **Paris**.\\n\"\n
        \         }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\":
        \"STOP\",\n      \"avgLogprobs\": -0.0012543704360723495\n    }\n  ],\n  \"usageMetadata\":
        {\n    \"promptTokenCount\": 12,\n    \"candidatesTokenCount\": 9,\n    \"totalTokenCount\":
        21,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n
        \       \"tokenCount\": 12\n      }\n    ],\n    \"candidatesTokensDetails\":
        [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 9\n      }\n
        \   ]\n  },\n  \"modelVersion\": \"gemini-2.0-flash\",\n  \"responseId\":
        \"3glmaPjNOc6BnvgPyLjriQ0\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Thu, 03 Jul 2025 04:41:03 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=392
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '683'
    status:
      code: 200
      message: OK
- request:
    body: '{"contents": [{"role": "user", "parts": [{"text": "What is the capital
      of France?"}]}], "generationConfig": {"temperature": 0}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '127'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - litellm/1.56.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=REDACTED
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"The capital of France is **Paris**.\\n\"\n
        \         }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\":
        \"STOP\",\n      \"avgLogprobs\": -0.027038529515266418\n    }\n  ],\n  \"usageMetadata\":
        {\n    \"promptTokenCount\": 7,\n    \"candidatesTokenCount\": 9,\n    \"totalTokenCount\":
        16,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n
        \       \"tokenCount\": 7\n      }\n    ],\n    \"candidatesTokensDetails\":
        [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 9\n      }\n
        \   ]\n  },\n  \"modelVersion\": \"gemini-2.0-flash\",\n  \"responseId\":
        \"3wlmaNjGJqTXnvgP3qGboAo\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Thu, 03 Jul 2025 04:41:03 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=441
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '680'
    status:
      code: 200
      message: OK
version: 1
